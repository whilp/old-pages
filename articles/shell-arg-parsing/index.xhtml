<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<title>Shell scripting patterns</title>
<link rel="home" href="../../"/> 
<link rel="copyright" href="../../copyright"/> 
<link rel="openid.delegate" href="http://openid.m.aier.us/will" />
<link rel="openid.server" href="http://www.myopenid.com/server" /> 
<link rel="stylesheet" type="text/css" href="../../css/site.css" />
<link rel="updates alternate" type="application/atom+xml" href="https://github.com/wcmaier/wcmaier.github.com/commits/master.atom"/> 
<!--[if IE]>
<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>
<body>

<article>

<header>
<hgroup>
<h1>Shell scripting patterns</h1>
</hgroup>
<nav>
<ul>
<li><strong><a href="../../">wcmaier</a></strong></li>
</ul>
</nav>

</header>

<p>
<a href="http://jehiah.cz/about">Jehiah</a>'s <a href="http://jehiah.cz/a/shell_script_args_parsing">post</a> about parsing arguments in shell scripts at <a href="http://bit.ly/">bit.ly</a> just came across the twitter-wire.
This got me thinking about the various patterns <a href="http://hep.wisc.edu/cms/comp">we</a> use to bring sanity to the mass of shell scripts that automate much of our cluster.
</p>

<p>
These patterns should apply to most (all?) Bourne-alike shells.
Most of our scripts are run by <code>/bin/sh</code> on Red Hat servers, though my personal scripting style is more informed by OpenBSD's <code>/bin/sh</code> (or <code>pdksh</code>).
</p>

<section>
<h1>Argument parsing</h1>

<p>
Since <a href="https://github.com/wcmaier/dotfiles/commit/7dcb570ddd4b8cc6c3cc5ba6a8b1f71e1cf617b8">late 2009</a>, I've stuck with a variation of the old <code>getopts</code> pattern.
The effect is similar to Jehiah's <code>while</code>/<code>awk</code> loop, but (in my opinion) reads a bit more clearly.
Here it is, in its most minimal incarnation:
</p>

<pre><code><![CDATA[
#!/bin/sh

SCRIPT="${0##*/}"

usage () {
    echo "${SCRIPT} [-h]"
}

while getopts h ARG; do
    case "${ARG}" in
        h) usage; exit 0;;
        *) usage; exit 1;;
    esac
done
shift $(($OPTIND - 1))
]]></code></pre>

<p>
Here, <code>-h</code> is a boolean option and anything after the options or <code>--</code> will be left in <code>$*</code>.
Unlike Jehiah's example, only single-character options are supported; as a BSD-first guy, that doesn't bother me much.
To add more options, update <code>usage()</code>, add the option (with a colon if it accepts an argument) to the <code>getopts</code> optstring and add a pattern to the <code>case</code> statement.
Positional arguments reside in the usual <code>$*</code>; the first argument after the option list is <code>$1</code>, as expected.
Note that <code>getopts</code> handles invalid options for you, so there's no need to print anything extra in the catch-all <code>*</code> case.
</p>

</section>

<section>
<h1>Logging</h1>

<p>
Lately, I've been feeling quite militant about logging in general and syslog in particular.
My syslog dogma warrants a separate post, but it's worth mentioning that it's very easy to incorporate good logging into your shell scripts using the argument parsing pattern above.
For example:
</p>

<pre><code><![CDATA[
#!/bin/sh

SCRIPT="${0##*/}"
IDENTITY="${SCRIPT}[$$]"
LOGGER="logger"
VERBOSE=

usage () {
    echo "${SCRIPT} [-hv]"
}

log () {
    echo "$*" | ${LOGGER} -t "${IDENTITY}"
}

while getopts hv ARG; do
    case "${ARG}" in
        h) usage; exit 0;;
        v) LOGGER="${LOGGER} -s"; VERBOSE=1;;
        *) usage; exit 1;;
    esac
done
shift $(($OPTIND - 1))

if [ -n "${VERBOSE}" ]; then
    exec >/dev/null 2>&1
fi
]]></code></pre>

<p>
I arrived at this logging pattern after DOSing our mail server one too many times with mails generated by failing cron jobs.
Unless the caller passes the <code>-v</code> option, the script will print <em>nothing at all</em>; instead, messages passed to the <code>log()</code> function will be sent to syslog where, I argue, they belong.
With <code>-v</code>, messages will be printed to stderr as well (see <code>logger(1)</code>).
Admittedly, this assumes that you've already spent the half-hour that it takes to properly configure logging.
</p>

</section>

<section>
<h1>Cleaning up</h1>

<p>
All scripts fail; the true measure of a script is how it handles the unexpected.
A well behaved script that fails should, if possible, clean up after itself and let someone know what happened.
This pattern involves creating a single temporary directory and installing a signal handler.
</p>

<p>
Why a temporary directory?
First, it makes cleanup easier: if every temporary file is found under a single directory, a simple <code>rm -rf</code> is all that's needed.
Second, you can securely create anything you want under a (correctly permissioned) temporary directory, even things like FIFOs that don't have their own <code>mktemp</code>.
So, early in our scripts, we create a temporary directory for use throughout the script:
</p>

<pre><code><![CDATA[
handle_exit () {
    rm -rf "${TMPDIR}"
}

TMPDIR=$(mktemp -d -p /tmp -d -p "${IDENTITY}.XXXXXXXXXX")
trap handle_exit EXIT
]]></code></pre>

<p>
This pattern gives us a private temporary work space and a reasonable guarantee that it won't get left behind when the script exits.
By defining <code>handle_exit()</code> and installing the signal handler when we create the temporary directory, we make it clear that each part is related.
Moreover, the use of the signal handler means we don't have to remember to code a cleanup at the end of the script ourselves.
</p>

<p>
Relatedly, we use boolean operators instead of <code>set -e</code> (the "errexit" shell option).
Using errexit can make debugging script failures quite difficult.
Indeed, there are many times where functions or commands are expected to return errors under normal conditions (as when, for example, a script calls <code>mkdir</code> to create a well-known directory whether or not it exists).
Chaining dependent statements with boolean operators is more explicit and flexible: 
</p>

<pre><code><![CDATA[
thing1 &&
thing2 &&
thing3 ||
handle_failure
]]></code></pre>

</section>

<section>
<h1>Statistics</h1>

<p>
Any script that takes more than a few minutes to run should probably log a brief summary of what it accomplished.
The data collected during the run will depend on the task at hand, but this simple pattern for tracking and summarizing runtime statistics should make reporting easier.
As we develop a script, we create any number of variables to store counters; we use a suffix naming convention to help them stand out later on.
</p>

<pre><code><![CDATA[
do_the_foo &&
let FOO_COUNTER+=1
]]></code></pre>

<p>
(We don't initialize these counters at all; the shell treats empty variables as 0.)
As we add these counters, we also add quick text summaries to a <code>summarize()</code> function.
Finally, we extend the previously defined <code>handle_exit()</code> function to call <code>summarize()</code>.
</p>

<pre><code><![CDATA[
summarize () {
    echo "We did the foo ${FOO_COUNTER:-0} times"
}

handle_exit () {
    summarize
    rm -rf "${TMPDIR}"
}
]]></code></pre>

</section>

<footer>
<dl>
<dt>Published</dt>
<dd><time pubdate="pubdate" datetime="2011-03-04T14:01-06:00">March 4, 2011</time></dd>
</dl>
<p><a href="../../copyright">Copyright</a> 2010.</p>
</footer>

</article>
</body>
</html>
